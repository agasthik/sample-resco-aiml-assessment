version: 0.2
phases:
  install:
    runtime-versions:
      python: 3.9
    commands:
      - pip install --upgrade pip
      - pip install --upgrade aws-sam-cli
  build:
    commands:
      - echo "Starting ReSCO AIML Assessment"
      - echo "Multi-account scan is $MULTI_ACCOUNT_SCAN"
      - cd resco-aiml-assessment
      - ls -la
      - sam build --use-container --template template-multi-account.yaml
      - echo "Build completed, checking build directory:"
      - ls -la .aws-sam/build/
      - |
        if [[ $MULTI_ACCOUNT_SCAN = 'true' ]]; then
          echo "Getting list of accounts to scan"
          if [[ $MULTI_ACCOUNT_LIST_OVERRIDE != '' ]]; then
            account_list=$MULTI_ACCOUNT_LIST_OVERRIDE
          else
            account_list=$(aws organizations list-accounts --query 'Accounts[?Status==`ACTIVE`].Id' --output text)
          fi
          echo "Will scan accounts: $account_list"
          for accountId in $account_list; do
            echo "Processing account $accountId"
            if [[ $accountId == $AWS_ACCOUNT_ID ]]; then
              echo "Skipping management account $accountId - will be handled separately"
              continue
            fi
            aws sts assume-role --role-arn arn:$AWS_PARTITION:iam::$accountId:role/service-role/$RESCO_ROLE --role-session-name ReSCOAssessment > /tmp/creds.json || continue
            export AWS_ACCESS_KEY_ID=$(cat /tmp/creds.json | jq -r '.Credentials.AccessKeyId')
            export AWS_SECRET_ACCESS_KEY=$(cat /tmp/creds.json | jq -r '.Credentials.SecretAccessKey')
            export AWS_SESSION_TOKEN=$(cat /tmp/creds.json | jq -r '.Credentials.SessionToken')
            echo "Deploying to account $accountId"
            aws cloudformation delete-stack --stack-name aws-sam-cli-managed-default || echo "No managed stack to delete in $accountId"
            sam deploy --template-file .aws-sam/build/template.yaml --stack-name resco-aiml-security-$accountId --capabilities CAPABILITY_IAM --no-confirm-changeset --resolve-s3 --parameter-overrides BucketName=$BUCKET_REPORT --region $AWS_DEFAULT_REGION || echo "Deploy failed for $accountId"
            STATE_MACHINE_ARN=$(aws cloudformation describe-stacks --stack-name resco-aiml-security-$accountId --query 'Stacks[0].Outputs[?OutputKey==`AIMLAssessmentStateMachineArn`].OutputValue' --output text 2>/dev/null)
            if [[ $STATE_MACHINE_ARN != "" ]]; then
              EXECUTION_ARN=$(aws stepfunctions start-execution --state-machine-arn $STATE_MACHINE_ARN --input "{\"accountId\":\"$accountId\"}" --query 'executionArn' --output text)
              echo "Started execution: $EXECUTION_ARN"
            fi
            unset AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN
          done
          echo "Deploying to management account $AWS_ACCOUNT_ID"
          sam deploy --template-file .aws-sam/build/template.yaml --stack-name resco-aiml-security-mgmt --capabilities CAPABILITY_IAM --no-confirm-changeset --s3-bucket $BUCKET_REPORT --parameter-overrides BucketName=$BUCKET_REPORT --region $AWS_DEFAULT_REGION || echo "Deploy failed for management account"
          STATE_MACHINE_ARN=$(aws cloudformation describe-stacks --stack-name resco-aiml-security-mgmt --query 'Stacks[0].Outputs[?OutputKey==`AIMLAssessmentStateMachineArn`].OutputValue' --output text 2>/dev/null)
          if [[ $STATE_MACHINE_ARN != "" ]]; then
            MGMT_EXECUTION_ARN=$(aws stepfunctions start-execution --state-machine-arn $STATE_MACHINE_ARN --input "{\"accountId\":\"$AWS_ACCOUNT_ID\"}" --query 'executionArn' --output text)
            echo "Started management account execution: $MGMT_EXECUTION_ARN"
          fi
        else
          echo "Single account deployment"
          sam deploy --template-file .aws-sam/build/template.yaml --stack-name resco-aiml-security --capabilities CAPABILITY_IAM --no-confirm-changeset --s3-bucket $BUCKET_REPORT --parameter-overrides BucketName=$BUCKET_REPORT
          STATE_MACHINE_ARN=$(aws cloudformation describe-stacks --stack-name resco-aiml-security --query 'Stacks[0].Outputs[?OutputKey==`AIMLAssessmentStateMachineArn`].OutputValue' --output text)
          aws stepfunctions start-execution --state-machine-arn $STATE_MACHINE_ARN --input "{\"accountId\":\"$AWS_ACCOUNT_ID\"}"
        fi
  post_build:
    commands:
      - echo "Assessment completed. Results in S3:$BUCKET_REPORT"
      - |
        if [[ $MULTI_ACCOUNT_SCAN = 'true' ]]; then
          echo "Getting list of accounts to scan"
          if [[ $MULTI_ACCOUNT_LIST_OVERRIDE != '' ]]; then
            account_list=$MULTI_ACCOUNT_LIST_OVERRIDE
          else
            account_list=$(aws organizations list-accounts --query 'Accounts[?Status==`ACTIVE`].Id' --output text)
          fi
          echo "Account list for post-build processing: $account_list"

          # Clean up any existing account-files directory to ensure fresh start
          echo "Cleaning up existing account-files directory"
          rm -rf /tmp/account-files
          mkdir -p /tmp/account-files

          # Function to wait for Step Function completion
          wait_for_execution() {
            local account_id=$1
            local stack_name=$2
            local timeout=300

            STATE_MACHINE_ARN=$(aws cloudformation describe-stacks --stack-name $stack_name --query 'Stacks[0].Outputs[?OutputKey==`AIMLAssessmentStateMachineArn`].OutputValue' --output text 2>/dev/null)
            if [[ $STATE_MACHINE_ARN != "" ]]; then
              echo tsaiting for Step Function completion in account $account_id..."
              EXECUTION_ARN=$(aws stepfunctions list-executions --state-machine-arn $STATE_MACHINE_ARN --status-filter RUNNING --max-items 1 --query 'executions[0].executionArn' --output text 2>/dev/null)
              if [[ $EXECUTION_ARN != "" && $EXECUTION_ARN != "None" ]]; then
                elapsed=0
                while [[ $elapsed -lt $timeout ]]; do
                  STATUS=$(aws stepfunctions describe-execution --execution-arn $EXECUTION_ARN --query 'status' --output text 2>/dev/null)
                  if [[ $STATUS == "SUCCEEDED" || $STATUS == "FAILED" || $STATUS == "TIMED_OUT" || $STATUS == "ABORTED" ]]; then
                    echo "Step Function for account $account_id completed with status: $STATUS"
                    return 0
                  fi
                  sleep 30
                  elapsed=$((elapsed + 30))
                done
                echo "Timeout waiting for account $account_id"
              fi
            fi
          }

          # Function to copy files from account bucket
          copy_account_files() {
            local account_id=$1
            local stack_name=$2

            ACCOUNT_BUCKET=$(aws cloudformation describe-stacks --stack-name $stack_name --query 'Stacks[0].Outputs[?OutputKey==`AssessmentBucketName`].OutputValue' --output text 2>/dev/null)
            if [[ $ACCOUNT_BUCKET != "" ]]; then
              echo "Syncing files from s3://$ACCOUNT_BUCKET/ for account $account_id"
              mkdir -p /tmp/account-files/$account_id

              # Use sync instead of cp for better performance and idempotency
              aws s3 sync s3://$ACCOUNT_BUCKET/ /tmp/account-files/$account_id/ \
                --exclude "*" \
                --include "*.csv" \
                --include "*.html" \
                --no-progress \
                --only-show-errors || echo "Warning: Sync failed for $account_id"

              # Flatten directory structure in one operation
              if [[ -d /tmp/account-files/$account_id ]]; then
                find /tmp/account-files/$account_id -mindepth 2 -type f \( -name "*.csv" -o -name "*.html" \) -exec mv -t /tmp/account-files/$account_id/ {} + 2>/dev/null || true
                find /tmp/account-files/$account_id -mindepth 1 -type d -empty -delete 2>/dev/null || true
                echo "Synced $(find /tmp/account-files/$account_id -maxdepth 1 -type f | wc -l) files for account $account_id"
              fi
            else
              echo "No assessment bucket found for $account_id"
            fi
          }

          echo "Processing accounts in parallel batches"
          # Process accounts in batches for better performance
          batch_size=5
          account_array=($account_list)
          total_accounts=${#account_array[@]}

          for ((i=0; i<$total_accounts; i+=$batch_size)); do
            batch_end=$((i + batch_size))
            [[ $batch_end -gt $total_accounts ]] && batch_end=$total_accounts

            echo "Processing batch: accounts $((i+1)) to $batch_end of $total_accounts"

            # Process batch in parallel
            for ((j=i; j<$batch_end; j++)); do
              accountId=${account_array[$j]}
              (
                echo "Processing account $accountId"
                if [[ $accountId == $AWS_ACCOUNT_ID ]]; then
                  STACK_NAME="resco-aiml-security-mgmt"
                  wait_for_execution "$accountId" "$STACK_NAME"
                  copy_account_files "$accountId" "$STACK_NAME"
                else
                  # Assume role for member account
                  if aws sts assume-role --role-arn arn:$AWS_PARTITION:iam::$accountId:role/service-role/$RESCO_ROLE --role-session-name ReSCOAssessment > /tmp/creds-$accountId.json 2>/dev/null; then
                    export AWS_ACCESS_KEY_ID=$(jq -r '.Credentials.AccessKeyId' /tmp/creds-$accountId.json)
                    export AWS_SECRET_ACCESS_KEY=$(jq -r '.Credentials.SecretAccessKey' /tmp/creds-$accountId.json)
                    export AWS_SESSION_TOKEN=$(jq -r '.Credentials.SessionToken' /tmp/creds-$accountId.json)

                    STACK_NAME="resco-aiml-security-$accountId"
                    wait_for_execution "$accountId" "$STACK_NAME"
                    copy_account_files "$accountId" "$STACK_NAME"

                    rm -f /tmp/creds-$accountId.json
                  else
                    echo "Failed to assume role for account $accountId"
                  fi
                fi
              ) &
            done

            # Wait for batch to complete
            wait
            echo "Batch complete"
          done

          echo "All account file copies completed"

          echo "Uploading files to management account S3 bucket and creating consolidated report"
          pip3 install beautifulsoup4

          # Debug: Show which directories exist
          echo "Available account directories:"
          ls -la /tmp/account-files/ || echo "No account-files directory"

          # Batch upload files to management account bucket using sync
          echo "Uploading consolidated files to s3://$BUCKET_REPORT/"

          # Count total files to upload
          total_files=$(find /tmp/account-files -type f | wc -l)
          echo "Uploading $total_files files from all accounts"

          # Use single sync operation for all accounts (much faster than individual syncs)
          if [[ -d /tmp/account-files ]]; then
            # Sync entire directory structure in one operation
            aws s3 sync /tmp/account-files/ s3://$BUCKET_REPORT/ \
              --delete \
              --no-progress \
              --only-show-errors || echo "Warning: Batch upload encountered errors"

            echo "Upload completed successfully"
          else
            echo "No files to upload"
          fi

          # Create consolidated HTML report using separate script
          python3 ../consolidate_html_reports.py
        fi
      - echo "Assessment and consolidation completed"
